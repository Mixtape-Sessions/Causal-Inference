filter(bac1>0.03 & bac1<0.13)
(white <- feols(white ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
(male <- feols(male ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
(aged <- feols(aged ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
(acc <- feols(acc ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
# Regression Table (LaTeX File)
fixest::etable(white, male, aged, acc,
title = "Regression Discontinuity Estimates for the Effect of Exceeding BAC Thresholds on Predetermined Characteristics",
tex = T,
file = "hansen_predetermined_covariates.tex")
rdrobust aged bac1 if bac1>0.03 & bac1<0.13, c(0.08) kernel(uniform) h(0.05)
#######################################################################################
# name: hansen.R
# author: scott cunningham (baylor)
# description: recreates (but doesn't replicate) several tables and figures from Hansen
#              2015 article in the AER on DWI and deterrence using RDD.
# last updated: january 16, 2022
#######################################################################################
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
install.packages(rdrobust)
install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
hansen$dwi <- hansen$bac1>=0.08
hansen_subset <- hansen %>%
filter(bac1>0.03 & bac1<0.13)
rdrobust aged bac1 if bac1>0.03 & bac1<0.13, c(0.08) kernel(uniform) h(0.05)
## Question 3. Make Figure 2 panels A to D using both linear and quadratic fits
#plotting
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08, TRUE ~ 0))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
categories <- hansen_subset$bac1
demmeans <- split(hansen_subset$recidivism, cut(hansen_subset$bac1, 0.449)) %>%
lapply(mean) %>%
unlist()
demmeans <- split(hansen_subset$recidivism, cut(hansen_subset$bac1, 0.08)) %>%
lapply(mean) %>%
unlist()
# install.packages("tidyverse")
# install.packages("haven")
# install.packages("estimatr")
library(tidyverse)
library(haven)
library(estimatr)
read_data <- function(df)
{
full_path <- paste("https://raw.github.com/scunning1975/mixtape/master/",
df, sep = "")
df <- read_dta(full_path)
return(df)
}
lmb_data <- read_data("lmb-data.dta")
lmb_subset <- lmb_data %>%
filter(lagdemvoteshare>.48 & lagdemvoteshare<.52)
lm_1 <- lm_robust(score ~ lagdemocrat, data = lmb_subset, clusters = id)
lm_2 <- lm_robust(score ~ democrat, data = lmb_subset, clusters = id)
lm_3 <- lm_robust(democrat ~ lagdemocrat, data = lmb_subset, clusters = id)
summary(lm_1)
summary(lm_2)
summary(lm_3)
#using all data (note data used is lmb_data, not lmb_subset)
lm_1 <- lm_robust(score ~ lagdemocrat, data = lmb_data, clusters = id)
lm_2 <- lm_robust(score ~ democrat, data = lmb_data, clusters = id)
lm_3 <- lm_robust(democrat ~ lagdemocrat, data = lmb_data, clusters = id)
summary(lm_1)
summary(lm_2)
summary(lm_3)
lmb_data <- lmb_data %>%
mutate(demvoteshare_c = demvoteshare - 0.5)
lm_1 <- lm_robust(score ~ lagdemocrat + demvoteshare_c, data = lmb_data, clusters = id)
lm_2 <- lm_robust(score ~ democrat + demvoteshare_c, data = lmb_data, clusters = id)
lm_3 <- lm_robust(democrat ~ lagdemocrat + demvoteshare_c, data = lmb_data, clusters = id)
summary(lm_1)
summary(lm_2)
summary(lm_3)
lm_1 <- lm_robust(score ~ lagdemocrat*demvoteshare_c,
data = lmb_data, clusters = id)
lm_2 <- lm_robust(score ~ democrat*demvoteshare_c,
data = lmb_data, clusters = id)
lm_3 <- lm_robust(democrat ~ lagdemocrat*demvoteshare_c,
data = lmb_data, clusters = id)
summary(lm_1)
summary(lm_2)
summary(lm_3)
lmb_data <- lmb_data %>%
mutate(demvoteshare_sq = demvoteshare_c^2)
lmb_data <- lmb_data %>%
mutate(lagdemvoteshare_c = lagdemvoteshare - 0.5)
lmb_data <- lmb_data %>%
mutate(lagdemvoteshare_sq = lagdemvoteshare_c^2)
lm_1 <- lm_robust(score ~ lagdemocrat*lagdemvoteshare_c + lagdemocrat*lagdemvoteshare_sq,
data = lmb_data, clusters = id)
lm_2 <- lm_robust(score ~ democrat*demvoteshare_c + democrat*demvoteshare_sq,
data = lmb_data, clusters = id)
lm_3 <- lm_robust(democrat ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq,
data = lmb_data, clusters = id)
summary(lm_1)
summary(lm_2)
summary(lm_3)
lmb_data %>%
filter(demvoteshare > .45 & demvoteshare < .55) %>%
mutate(demvoteshare_sq = demvoteshare_c^2)
lm_1 <- lm_robust(score ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq,
data = lmb_data, clusters = id)
lm_2 <- lm_robust(score ~ democrat*demvoteshare_c + democrat*demvoteshare_sq,
data = lmb_data, clusters = id)
lm_3 <- lm_robust(democrat ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq,
data = lmb_data, clusters = id)
summary(lm_1)
summary(lm_2)
summary(lm_3)
categories <- lmb_data$lagdemvoteshare
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
## Load Hansen's dataset into memory
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
# List the variables
str(hansen)
## Question 1
# 1a. Generate a dummy variable.  bac1>=0.08
hansen$dwi <- hansen$bac1>=0.08
#hansen$dwi[is.na(hansen$dwi)] <- 0
install.packages("rdrobust")
hansen_subset <- hansen %>%
filter(bac1>0.03 & bac1<0.13)
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
#######################################################################################
# name: hansen.R
# author: scott cunningham (baylor)
# description: recreates (but doesn't replicate) several tables and figures from Hansen
#              2015 article in the AER on DWI and deterrence using RDD.
# last updated: january 16, 2022
#######################################################################################
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
#install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
## Load Hansen's dataset into memory
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
# List the variables
str(hansen)
## Question 1
# 1a. Generate a dummy variable.  bac1>=0.08
hansen$dwi <- hansen$bac1>=0.08
#hansen$dwi[is.na(hansen$dwi)] <- 0
hansen_subset <- hansen %>%
filter(bac1>0.03 & bac1<0.13)
(acc <- feols(acc ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
(acc <- feols(acc ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
(aged <- feols(aged ~ bac1*dwi, data=hansen_subset, vcov="HC1"))
tall.packages("estimatr")
library(tidyverse)
library(haven)
library(estimatr)
read_data <- function(df)
{
full_path <- paste("https://raw.github.com/scunning1975/mixtape/master/",
df, sep = "")
df <- read_dta(full_path)
return(df)
}
lmb_data <- read_data("lmb-data.dta")
lmb_subset <- lmb_data %>%
filter(lagdemvoteshare>.48 & lagdemvoteshare<.52)
#aggregating the data
categories <- lmb_data$lagdemvoteshare
demmeans <- split(lmb_data$score, cut(lmb_data$lagdemvoteshare, 100)) %>%
lapply(mean) %>%
unlist()
#######################################################################################
# name: hansen.R
# author: scott cunningham (baylor)
# description: recreates (but doesn't replicate) several tables and figures from Hansen
#              2015 article in the AER on DWI and deterrence using RDD.
# last updated: january 16, 2022
#######################################################################################
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
#install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
## Load Hansen's dataset into memory
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
# List the variables
str(hansen)
## Question 1
# 1a. Generate a dummy variable.  bac1>=0.08
hansen$dwi <- hansen$bac1>=0.08
#hansen$dwi[is.na(hansen$dwi)] <- 0
hansen_subset <- hansen %>%
filter(bac1>0.03 & bac1<0.13)
categories <- hansen_subset$bac1
means <- split(hansen_subset$recidivism, cut(hansen_subset$bac1, 100)) %>%
lapply(mean) %>%
unlist()
agg_data <- data.frame(recidivism = means, bac1 = seq(0.01,1, by = 0.01))
agg_data <- data.frame(recidivism = means, bac1 = seq(0.01,0.5, by = 0.01))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.5, TRUE ~ 0))
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,1) + ylim(0,0.5) +
geom_vline(xintercept = 0.08)
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,1.5) + ylim(0,0.2) +
geom_vline(xintercept = 0.08)
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,0.5) + ylim(0,0.2) +
geom_vline(xintercept = 0.08)
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,0.5) + ylim(0,0.14) +
agg_data <- data.frame(recidivism = means, bac1 = seq(0.01,0.14, by = 0.01))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,0.5) + ylim(0,0.14) +
geom_vline(xintercept = 0.08)
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,0.14) + ylim(0,0.2) +
geom_vline(xintercept = 0.08)
#aggregating the data
categories <- hansen_subset$bac1
means <- split(hansen_subset$recidivism, cut(hansen_subset$bac1, 100)) %>%
lapply(mean) %>%
unlist()
agg_data <- data.frame(recidivism = means, bac1 = seq(0.01,0.14, by = 0.01))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,0.14) + ylim(0,0.15) +
geom_vline(xintercept = 0.08)
#aggregating the data
categories <- hansen_subset$bac1
means <- split(hansen_subset$recidivism, cut(hansen_subset$bac1, 100)) %>%
lapply(mean) %>%
unlist()
agg_data <- data.frame(recidivism = means, bac1 = seq(0.01,0.14, by = 0.001))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
ggplot(hansen_subset, aes(bac1, recidivism)) +
geom_point(aes(x = bac1, y = recidivism), data = agg_data) +
stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm",
formula = y ~ x + I(x^2)) +
xlim(0,0.14) + ylim(0,0.15) +
geom_vline(xintercept = 0.08)
#aggregating the data
categories <- hansen_subset$bac1
means <- split(hansen_subset$recidivism, cut(hansen_subset$bac1, 1)) %>%
lapply(mean) %>%
unlist()
mutate(bac_bin = cut(bac1, breaks = seq(.03,.13, by=.001))) %>%
group_by(bac_bin) %>%
mutate(acc = mean(acc),
male = mean(male),
age = mean(aged),
white = mean(white),
recidivism = mean(recidivism))
hansen_subset <- hansen_subset %>%
mutate(gg_group = case_when(bac1 > 0.08 ~ 0.14, TRUE ~ 0))
mutate(bac_bin = cut(bac1, breaks = seq(.03,.13, by=.001))) %>%
group_by(bac_bin) %>%
mutate(acc = mean(acc),
male = mean(male),
age = mean(aged),
white = mean(white),
recidivism = mean(recidivism))
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
mutate(bac_bin = cut(bac1, breaks = seq(.03,.13, by=.001))) %>%
group_by(bac_bin) %>%
mutate(acc = mean(acc),
male = mean(male),
age = mean(aged),
white = mean(white),
recidivism = mean(recidivism))
hansen %>%
mutate(bac_bin = cut(bac1, breaks = seq(.03,.13, by=.001))) %>%
group_by(bac_bin) %>%
mutate(acc = mean(acc),
male = mean(male),
age = mean(aged),
white = mean(white),
recidivism = mean(recidivism))
#######################################################################################
# name: hansen.R
# author: scott cunningham (baylor)
# description: recreates (but doesn't replicate) several tables and figures from Hansen
#              2015 article in the AER on DWI and deterrence using RDD.
# last updated: january 16, 2022
#######################################################################################
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
#install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
## Load Hansen's dataset into memory
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
# List the variables
str(hansen)
dwi_binned <- dwi %>% filter(between(bac1, 0, 0.15))
x_bin <- length(seq(0, max(dwi_binned$bac1), by=0.002)) %>%
cut(dwi_binned$bac1, breaks=., include.lowest = T) %>% as.integer()
dwi_binned$x_bin <- x_bin
dwi_binned <- dwi_binned[order(dwi_binned$x_bin), ] %>%
select(male, white, acc, aged, recidivism, x_bin, bac1, dui)
dwi_binned <- aggregate(. ~ x_bin, dwi_binned, mean)
dwi_binned$dui <- round(dwi_binned$dui)
ggplot(dwi_binned, aes(x=bac1, y=recidivism)) + geom_point() + ggtitle("Recidivism") +
geom_smooth(aes(group = dui), method = "lm", formula= "y ~ x", se = F)
dwi_binned <- dwi %>% filter(between(bac1, 0, 0.15))
#######################################################################################
# name: hansen.R
# author: scott cunningham (baylor)
# description: recreates (but doesn't replicate) several tables and figures from Hansen
#              2015 article in the AER on DWI and deterrence using RDD.
# last updated: january 16, 2022
#######################################################################################
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
#install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
## Load Hansen's dataset into memory
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
# List the variables
str(hansen)
## Question 1
# 1a. Generate a dummy variable.  bac1>=0.08
hansen$dwi <- hansen$bac1>=0.08
#hansen$dwi[is.na(hansen$dwi)] <- 0
dwi_binned <- dwi %>% filter(between(bac1, 0, 0.15))
x_bin <- length(seq(0, max(dwi_binned$bac1), by=0.002)) %>%
cut(dwi_binned$bac1, breaks=., include.lowest = T) %>% as.integer()
dwi_binned$x_bin <- x_bin
dwi_binned <- dwi_binned[order(dwi_binned$x_bin), ] %>%
select(male, white, acc, aged, recidivism, x_bin, bac1, dui)
dwi_binned <- aggregate(. ~ x_bin, dwi_binned, mean)
dwi_binned$dui <- round(dwi_binned$dui)
ggplot(dwi_binned, aes(x=bac1, y=recidivism)) + geom_point() + ggtitle("Recidivism") +
geom_smooth(aes(group = dui), method = "lm", formula= "y ~ x", se = F)
dwi_binned <- dwi %>% filter(between(bac1, 0, 0.15))
dwi_binned <- hansen %>% filter(between(bac1, 0, 0.15))
#######################################################################################
# name: hansen.R
# author: scott cunningham (baylor)
# description: recreates (but doesn't replicate) several tables and figures from Hansen
#              2015 article in the AER on DWI and deterrence using RDD.
# last updated: january 16, 2022
#######################################################################################
#install.packages("readstata13")
#install.packages("httpgd")
#install.packages("languageserver")
#install.packages("fixest")
#if (!requireNamespace("remotes")) {
#  install.packages("remotes")
#}
#remotes::install_github("kolesarm/RDHonest", force=TRUE)
#install.packages("rdrobust")
library(readstata13)
library(tidyverse)
library(haven)
library(fixest) # fixest is the go to for estimation in R
library(RDHonest)
library(ggplot2)
library(rdrobust)
## Load Hansen's dataset into memory
hansen <- read_dta("https://github.com/scunning1975/mixtape/raw/master/hansen_dwi.dta")
setwd('/users/scott_cunningham/Documents/Causal-Inference/Automation')
getwd()
#create dummy
df<-
df %>%
mutate(dui = if_else(bac1>=.08, 1, 0))
#make variables into grouped means
df<-
df %>%
filter(bac1>=.03 & bac1<=.13) %>%
select(bac1, acc, male, aged, white, dui, recidivism) %>%
mutate(bac_bin = cut(bac1, breaks = seq(.03,.13, by=.001))) %>%
group_by(bac_bin) %>%
mutate(acc = mean(acc),
male = mean(male),
age = mean(aged),
white = mean(white),
recidivism = mean(recidivism))
#look at bac by recidivism
df %>%
ggplot(aes(x=bac_bin, y=recidivism)) +
geom_point()
reticulate::repl_python()
